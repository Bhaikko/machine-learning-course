{"cells":[{"cell_type":"markdown","metadata":{"id":"VQ3syspj_rKn","colab_type":"text"},"source":["# Principal Component Analysis (PCA)"]},{"cell_type":"markdown","metadata":{"id":"xJGl9TcT_skx","colab_type":"text"},"source":["## Importing the libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np \n","import matplotlib.pyplot as plt \n","import pandas as pd "]},{"cell_type":"markdown","metadata":{"id":"Hyp1gza1_6qX","colab_type":"text"},"source":["## Importing the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = pd.read_csv('Wine.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"markdown","metadata":{"id":"1wrHODfJAEiI","colab_type":"text"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2)"]},{"cell_type":"markdown","metadata":{"id":"3bUhSHktAcOe","colab_type":"text"},"source":["## Feature Scaling"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"S3i3lRiwASAX","colab_type":"text"},"source":["## Applying PCA"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","# Number of Principal Components that is, number of extracted features\n","pca = PCA(n_components = 2)\n","\n","# both training and test set should be used to extract principal components. \n","X_train = pca.fit_transform(X_train)\n","X_test = pca.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"UBx16JVLAuel","colab_type":"text"},"source":["## Training the Logistic Regression model on the Training set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","classifier = LogisticRegression(random_state = 0)\n","classifier.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"37ouVXGHBGAg","colab_type":"text"},"source":["## Predicting the Test set results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = classifier.predict(X_test)\n","\n","print(np.concatenate(\n","    (y_pred.reshape(len(y_pred), 1),\n","    y_test.reshape(len(y_test), 1)),\n","    axis = 1\n","))"]},{"cell_type":"markdown","metadata":{"id":"MTck416XBPnD","colab_type":"text"},"source":["## Making the Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, accuracy_score\n","y_pred = classifier.predict(X_test)\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"h6pZMBrUBXwb","colab_type":"text"},"source":["## Visualising the Training set results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.colors import ListedColormap\n","X_set, y_set = X_train, y_train\n","X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 1),\n","                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 1))\n","plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n","             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\n","plt.xlim(X1.min(), X1.max())\n","plt.ylim(X2.min(), X2.max())\n","for i, j in enumerate(np.unique(y_set)):\n","    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n","                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n","plt.title('Logistic Regression (Training set)')\n","plt.xlabel('PC1')\n","plt.ylabel('PC2')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"-Dbzx_KqBguX","colab_type":"text"},"source":["## Visualising the Test set results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.colors import ListedColormap\n","X_set, y_set = X_test, y_test\n","X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 1),\n","                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 1))\n","plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n","             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\n","plt.xlim(X1.min(), X1.max())\n","plt.ylim(X2.min(), X2.max())\n","for i, j in enumerate(np.unique(y_set)):\n","    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n","                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n","plt.title('Logistic Regression (Test set)')\n","plt.xlabel('PC1')\n","plt.ylabel('PC2')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"Principal Component Analysis","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPY+Ntw06tAv5AOB9Ipnvzq"},"kernelspec":{"name":"python36964bit1162f47d6e97438b80359b44d90c2639","display_name":"Python 3.6.9 64-bit"}},"nbformat":4,"nbformat_minor":0}