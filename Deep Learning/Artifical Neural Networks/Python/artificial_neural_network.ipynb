{"cells":[{"cell_type":"markdown","metadata":{"id":"lP6JLo1tGNBg","colab_type":"text"},"source":["# Artificial Neural Network"]},{"cell_type":"markdown","metadata":{"id":"gWZyYmS_UE_L","colab_type":"text"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import tensorflow as tf "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"1E0Q3aoKUCRX","colab_type":"text"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"cKWAkFVGUU0Z","colab_type":"text"},"source":["### Importing the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = pd.read_csv('Churn_Modelling.csv')\n","X = dataset.iloc[:, 3:-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(y)"]},{"cell_type":"markdown","metadata":{"id":"N6bQ0UgSU-NJ","colab_type":"text"},"source":["### Encoding categorical data"]},{"cell_type":"markdown","metadata":{"id":"le5MJreAbW52","colab_type":"text"},"source":["Label Encoding the \"Gender\" column"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# No missing data in dataset\n","\n","# Since gender is binary value\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","\n","X[:, 2] = le.fit_transform(X[:, 2])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X)"]},{"cell_type":"markdown","metadata":{"id":"CUxGZezpbMcb","colab_type":"text"},"source":["One Hot Encoding the \"Geography\" column"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","ct = ColumnTransformer(\n","    transformers = [(\n","        'encoder',\n","        OneHotEncoder(),\n","        [1]                 # index of column to apply one hot encoding\n","    )],\n","    remainder = 'passthrough'\n",")\n","\n","X = np.array(ct.fit_transform(X))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X)"]},{"cell_type":"markdown","metadata":{"id":"RE_FcHyfV3TQ","colab_type":"text"},"source":["### Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"]},{"cell_type":"markdown","metadata":{"id":"vHol938cW8zd","colab_type":"text"},"source":["### Feature Scaling"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Feature scaling is fundamental for deep learning even for dummy variables\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"-zfEzkRVXIwF","colab_type":"text"},"source":["## Part 2 - Building the ANN"]},{"cell_type":"markdown","metadata":{"id":"KvdeScabXtlB","colab_type":"text"},"source":["### Initializing the ANN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ann = tf.keras.models.Sequential()              # Initialsing the artifical Neural network using Sequential Class"]},{"cell_type":"markdown","metadata":{"id":"rP6urV6SX7kS","colab_type":"text"},"source":["### Adding the input layer and the first hidden layer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Adding a layer in network\n","ann.add(tf.keras.layers.Dense(\n","    units = 6,                                   # Number of neurons which is based on experiments\n","    activation = 'relu'                          # Rectifier activation function \n","))"]},{"cell_type":"markdown","metadata":{"id":"BELWAc_8YJze","colab_type":"text"},"source":["### Adding the second hidden layer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(\n","    units = 6,                                   \n","    activation = 'relu'                          \n","))"]},{"cell_type":"markdown","metadata":{"id":"OyNEe6RXYcU4","colab_type":"text"},"source":["### Adding the output layer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(\n","    units = 1,                                   \n","    activation = 'sigmoid'                          \n","))"]},{"cell_type":"markdown","metadata":{"id":"JT4u2S1_Y4WG","colab_type":"text"},"source":["## Part 3 - Training the ANN"]},{"cell_type":"markdown","metadata":{"id":"8GWlJChhY_ZI","colab_type":"text"},"source":["### Compiling the ANN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\n","# categorical_crossentropy for categorical outcome"]},{"cell_type":"markdown","metadata":{"id":"0QR_G5u7ZLSM","colab_type":"text"},"source":["### Training the ANN on the Training set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ann.fit(X_train, y_train, batch_size = 32, epochs = 50)"]},{"cell_type":"markdown","metadata":{"id":"tJj5k2MxZga3","colab_type":"text"},"source":["## Part 4 - Making the predictions and evaluating the model"]},{"cell_type":"markdown","metadata":{},"source":["### Predicting the result of single observation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["singleTest = np.array([[\n","    600,\n","    'France',\n","    'Male',\n","    40,\n","    3,\n","    60000,\n","    2,\n","    1,\n","    1,\n","    50000\n","]])\n","# print(singleTest)\n","\n","singleTest[:, 2] = le.transform(singleTest[:, 2])\n","singleTest = np.array(ct.transform(singleTest))\n","\n","singleTest = sc.transform(singleTest)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(singleTest)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ann.predict(singleTest)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Mentor solution \n","ann.predict(sc.transform([[\n","    1, 0, 0,\n","    600,\n","    1,\n","    40,\n","    3,\n","    60000,\n","    2,\n","    1,\n","    1,\n","    50000\n","]]))"]},{"cell_type":"markdown","metadata":{"id":"u7yx47jPZt11","colab_type":"text"},"source":["### Predicting the Test set results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = ann.predict(X_test)\n","y_pred = (y_pred > 0.5)\n","print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1))"]},{"cell_type":"markdown","metadata":{"id":"o0oyfLWoaEGw","colab_type":"text"},"source":["### Making the Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, accuracy_score\n","\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","\n","accuracy_score(y_test, y_pred)"]}],"metadata":{"colab":{"name":"artificial_neural_network.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNwEZ4u/dqMJg76I+Be0fpv"},"kernelspec":{"name":"python36964bit1162f47d6e97438b80359b44d90c2639","display_name":"Python 3.6.9 64-bit"}},"nbformat":4,"nbformat_minor":0}