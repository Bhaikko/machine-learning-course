{"cells":[{"cell_type":"markdown","metadata":{"id":"3DR-eO17geWu","colab_type":"text"},"source":["# Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"id":"EMefrVPCg-60","colab_type":"text"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf \n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"oxQxCBWyoGPE","colab_type":"text"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"y8K74-1foOic","colab_type":"text"},"source":["### Generating images for the Training set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Transformations are applied to avoid over fitting\n","# Eg, Rotations, flips, etc\n","# Image augmentation \n","\n","train_datagen = ImageDataGenerator(\n","    rescale = 1.0 / 255.0,              # Feature scaling to have values between [0, 1] of pixel colors\n","    shear_range = 0.2,\n","    zoom_range = 0.2,\n","    horizontal_flip = True \n",")\n","\n","training_set = train_datagen.flow_from_directory(\n","    'Data/training_set',\n","    target_size = (64, 64),\n","    batch_size = 32,                    # Batch is number of images taken in group as input in Neural network\n","    class_mode = 'binary'\n",")"]},{"cell_type":"markdown","metadata":{"id":"LXXei7qHornJ","colab_type":"text"},"source":["### Generating images for the Test set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Transformation are not applied to Test set\n","train_datagen = ImageDataGenerator(\n","    rescale = 1.0 / 255.0\n",")\n","\n","test_set = train_datagen.flow_from_directory(\n","    'Data/test_set',\n","    target_size = (64, 64),\n","    batch_size = 32,\n","    class_mode = 'binary'\n",")"]},{"cell_type":"markdown","metadata":{"id":"af8O4l90gk7B","colab_type":"text"},"source":["## Part 2 - Building the CNN"]},{"cell_type":"markdown","metadata":{"id":"ces1gXY2lmoX","colab_type":"text"},"source":["### Initialising the CNN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cnn = tf.keras.models.Sequential()"]},{"cell_type":"markdown","metadata":{"id":"u5YJj_XMl5LF","colab_type":"text"},"source":["### Step 1 - Convolution"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cnn.add(tf.keras.layers.Conv2D(\n","    filters = 32,\n","    kernel_size = 3,\n","    activation = 'relu',\n","    input_shape = [64, 64, 3]\n","))"]},{"cell_type":"markdown","metadata":{"id":"tf87FpvxmNOJ","colab_type":"text"},"source":["### Step 2 - Pooling"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cnn.add(tf.keras.layers.MaxPool2D(\n","    pool_size = 2,\n","    strides = 2\n","))"]},{"cell_type":"markdown","metadata":{"id":"xaTOgD8rm4mU","colab_type":"text"},"source":["### Adding a second convolutional layer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cnn.add(tf.keras.layers.Conv2D(\n","    filters = 32,\n","    kernel_size = 3,\n","    activation = 'relu'\n","))\n","\n","cnn.add(tf.keras.layers.MaxPool2D(\n","    pool_size = 2,\n","    strides = 2\n","))"]},{"cell_type":"markdown","metadata":{"id":"tmiEuvTunKfk","colab_type":"text"},"source":["### Step 3 - Flattening"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cnn.add(tf.keras.layers.Flatten())"]},{"cell_type":"markdown","metadata":{"id":"dAoSECOm203v","colab_type":"text"},"source":["### Step 4 - Full Connection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cnn.add(tf.keras.layers.Dense(\n","    units = 128,     # Number of neurons in this layer \n","    activation = 'relu'\n","))"]},{"cell_type":"markdown","metadata":{"id":"yTldFvbX28Na","colab_type":"text"},"source":["### Step 5 - Output Layer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cnn.add(tf.keras.layers.Dense(\n","    units = 1,\n","    activation = 'sigmoid'\n","))"]},{"cell_type":"markdown","metadata":{"id":"D6XkI90snSDl","colab_type":"text"},"source":["## Part 3 - Training the CNN"]},{"cell_type":"markdown","metadata":{"id":"vfrFQACEnc6i","colab_type":"text"},"source":["### Compiling the CNN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cnn.compile(\n","    optimizer = 'adam',\n","    loss = 'binary_crossentropy',\n","    metrics = ['accuracy']\n",")"]},{"cell_type":"markdown","metadata":{"id":"ehS-v3MIpX2h","colab_type":"text"},"source":["### Training the CNN on the Training set and evaluating it on the Test set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cnn.fit(x = training_set, validation_data = test_set, epochs = 15)"]},{"cell_type":"markdown","metadata":{},"source":["## Making a single prediction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np \n","from keras.preprocessing import image\n","\n","# Loads image in PIL format\n","test_image = image.load_img('Data/single_prediction/cat_or_dog_2.jpg', target_size = (64, 64))\n","test_image = image.img_to_array(test_image)         # A numpy 2d Array for predict method\n","test_image = np.expand_dims(test_image, axis = 0)           # adding batch to single image on 0 index\n","result = cnn.predict(test_image)\n","\n","# To figure out which index correspond to which class\n","training_set.class_indices      # prints the class and their index\n","\n","prediction = \"cat\"\n","if result[0][0] == 1:\n","    prediction = \"dog\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(prediction)"]}],"metadata":{"colab":{"name":"Convolutional Neural Network","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyN4RwM22jdD+NwpsDagcktL"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}